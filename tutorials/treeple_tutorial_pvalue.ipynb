{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5c9c9a",
   "metadata": {},
   "source": [
    "# Treeple tutorial for calculating p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1988c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sktree.datasets import make_trunk_classification\n",
    "from sktree.ensemble import HonestForestClassifier\n",
    "from sktree.stats import build_hyppo_oob_forest\n",
    "from treeple_tutorial_toolbox import Calculate_MI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a652d709",
   "metadata": {},
   "source": [
    "## Independence Testing\n",
    "\n",
    "Given samples from `X` and `Y`, the independent hypothesis and its alternative are stated as:\n",
    "\n",
    "$$H_0 : F_{XY} = F_X F_Y$$\n",
    "$$H_A : F_{XY} \\neq F_X F_Y$$\n",
    "\n",
    "By computing the p-value using `treeple`, we can test if $H_0$ would be rejected, which confirms the joint distribution. The p-vlaue is generated by comparing the observed statistic difference with permuted differences, using mutual information as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866142b4",
   "metadata": {},
   "source": [
    "## MI\n",
    "\n",
    "Mutual Information (*MI*) measures the mutual dependence between *X* and *Y*. It can be calculated by the difference between the class entropy (`H(Y)`) and the conditional entropy (`H(Y | X)`):\n",
    "\n",
    "$$I(X; Y) = H(Y) - H(Y\\mid X)$$\n",
    "\n",
    "With a binary class simulation as an example, this tutorial will show how to use `treeple` to use the statistic and test the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722a909",
   "metadata": {},
   "source": [
    "## Create a simulation with two gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36aef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary class simulation with two gaussians\n",
    "# 500 samples for each class, class zero is standard\n",
    "# gaussian, and class one has a mean at one\n",
    "X, y = make_trunk_classification(\n",
    "    n_samples=1000,\n",
    "    n_dim=1,\n",
    "    mu_0=0,\n",
    "    mu_1=1,\n",
    "    n_informative=1,\n",
    "    seed=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3d4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot the samples\n",
    "plt.hist(X[500:], bins=15, alpha=0.6, color=\"blue\", label=\"negative\")\n",
    "plt.hist(X[:500], bins=15, alpha=0.6, color=\"red\", label=\"positive\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cdc5ca",
   "metadata": {},
   "source": [
    "## Generate observed posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe0935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the forest with 100 trees\n",
    "est = HonestForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_samples=1.6,\n",
    "    max_features=0.3,\n",
    "    bootstrap=True,\n",
    "    stratify=True,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# fit the model and obtain the tree posteriors\n",
    "_, observe_proba = build_hyppo_oob_forest(est, X, y)\n",
    "\n",
    "# generate forest posteriors for the two classes\n",
    "observe_proba = np.nanmean(observe_proba, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345a4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot the posterior probabilities for class one\n",
    "plt.hist(observe_proba[:500][:, 1], bins=30, alpha=0.6, color=\"blue\", label=\"negative\")\n",
    "plt.hist(observe_proba[500:][:, 1], bins=30, alpha=0.6, color=\"red\", label=\"positive\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611b7c",
   "metadata": {},
   "source": [
    "## Generate null posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5022bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the labels\n",
    "X_null = np.copy(X)\n",
    "y_null = np.copy(y)\n",
    "np.random.shuffle(y_null)\n",
    "\n",
    "# initialize another forest with 100 trees\n",
    "est_null = HonestForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_samples=1.6,\n",
    "    max_features=0.3,\n",
    "    bootstrap=True,\n",
    "    stratify=True,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# fit the model and obtain the tree posteriors\n",
    "_, null_proba = build_hyppo_oob_forest(est, X_null, y_null)\n",
    "\n",
    "# generate forest posteriors for the two classes\n",
    "null_proba = np.nanmean(null_proba, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f1f6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot the posterior probabilities for class one\n",
    "plt.hist(null_proba[:500][:, 1], bins=30, alpha=0.6, color=\"blue\", label=\"negative\")\n",
    "plt.hist(null_proba[500:][:, 1], bins=30, alpha=0.6, color=\"red\", label=\"positive\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d9737",
   "metadata": {},
   "source": [
    "## Find the observed statistic difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa94559",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = Calculate_MI(y, observe_proba)\n",
    "mi_null = Calculate_MI(y, null_proba)\n",
    "\n",
    "observed_diff = mi - mi_null\n",
    "print(\"Observed statistic difference =\", round(observed_diff, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e2d1f",
   "metadata": {},
   "source": [
    "## Permute the tree posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ac2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERMUTE = 10000\n",
    "mix_diff = []\n",
    "\n",
    "# Collect all the tree posteriors\n",
    "proba = np.vstack((observe_proba, null_proba))\n",
    "for i in range(PERMUTE):\n",
    "\n",
    "    # permute the posteriors\n",
    "    np.random.shuffle(proba)\n",
    "\n",
    "    # calculate the statistic for\n",
    "    # the two mixed forest posteriors\n",
    "    mi_mix_one = Calculate_MI(y, proba[:100])\n",
    "    mi_mix_two = Calculate_MI(y, proba[100:])\n",
    "    mix_diff.append(mi_mix_one - mi_mix_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb51dd8",
   "metadata": {},
   "source": [
    "## Calculate the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = (1 + (mix_diff >= observed_diff).sum()) / (1 + PERMUTE)\n",
    "\n",
    "print(\"p-value is:\", round(pvalue, 2))\n",
    "if pvalue < 0.05:\n",
    "    print(\"The null hypothesis is rejected.\")\n",
    "else:\n",
    "    print(\"The null hypothesis is not rejected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
