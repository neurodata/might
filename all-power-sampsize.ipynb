{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981d0198-5f92-4cb2-a798-3d2fb8ced5b1",
   "metadata": {},
   "source": [
    "# Power vs. Sample Size for 14 Relationships - Supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f41bda0-c7c3-41fe-ad0b-cddce7fab2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os, sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib.legend import Legend\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.stats import entropy, norm, mstats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "from hyppo.independence import Dcorr\n",
    "from hyppo.ksample import k_sample_transform\n",
    "from sktree.ensemble import HonestForestClassifier\n",
    "from sktree.stats import FeatureImportanceForestClassifier\n",
    "\n",
    "from simulations import *\n",
    "\n",
    "sys.path.append(os.path.realpath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965a98fb-58a4-4345-8ab1-2d531a260b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal, entropy\n",
    "from scipy.integrate import nquad\n",
    "\n",
    "\n",
    "def make_trunk_classification(\n",
    "    n_samples,\n",
    "    n_dim=4096,\n",
    "    n_informative=1,\n",
    "    simulation: str = \"trunk\",\n",
    "    mu_0: float = 0,\n",
    "    mu_1: float = 1,\n",
    "    rho: int = 0,\n",
    "    band_type: str = \"ma\",\n",
    "    return_params: bool = False,\n",
    "    mix: float = 0.5,\n",
    "    seed=None,\n",
    "):\n",
    "    if n_dim < n_informative:\n",
    "        raise ValueError(\n",
    "            f\"Number of informative dimensions {n_informative} must be less than number \"\n",
    "            f\"of dimensions, {n_dim}\"\n",
    "        )\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    mu_0 = np.array([mu_0 / np.sqrt(i) for i in range(1, n_informative + 1)])\n",
    "    mu_1 = np.array([mu_1 / np.sqrt(i) for i in range(1, n_informative + 1)])\n",
    "\n",
    "    if rho != 0:\n",
    "        if band_type == \"ma\":\n",
    "            cov = _moving_avg_cov(n_informative, rho)\n",
    "        elif band_type == \"ar\":\n",
    "            cov = _autoregressive_cov(n_informative, rho)\n",
    "        else:\n",
    "            raise ValueError(f'Band type {band_type} must be one of \"ma\", or \"ar\".')\n",
    "    else:\n",
    "        cov = np.identity(n_informative)\n",
    "\n",
    "    if mix < 0 or mix > 1:\n",
    "        raise ValueError(\"Mix must be between 0 and 1.\")\n",
    "\n",
    "    # speed up computations for large multivariate normal matrix with SVD approximation\n",
    "    if n_informative > 1000:\n",
    "        method = \"cholesky\"\n",
    "    else:\n",
    "        method = \"svd\"\n",
    "\n",
    "    if simulation == \"trunk\":\n",
    "        X = np.vstack(\n",
    "            (\n",
    "                rng.multivariate_normal(mu_0, cov, n_samples // 2, method=method),\n",
    "                rng.multivariate_normal(mu_1, cov, n_samples // 2, method=method),\n",
    "            )\n",
    "        )\n",
    "    elif simulation == \"trunk_overlap\":\n",
    "        mixture_idx = rng.choice(2, n_samples // 2, replace=True, shuffle=True, p=[mix, 1 - mix])\n",
    "        norm_params = [[mu_0, cov], [mu_1, cov]]\n",
    "        X_mixture = np.fromiter(\n",
    "            (\n",
    "                rng.multivariate_normal(*(norm_params[i]), size=1, method=method)\n",
    "                for i in mixture_idx\n",
    "            ),\n",
    "            dtype=np.dtype((float, n_informative)),\n",
    "        )\n",
    "        X_mixture_2 = np.fromiter(\n",
    "            (\n",
    "                rng.multivariate_normal(*(norm_params[i]), size=1, method=method)\n",
    "                for i in mixture_idx\n",
    "            ),\n",
    "            dtype=np.dtype((float, n_informative)),\n",
    "        )\n",
    "\n",
    "        X = np.vstack(\n",
    "            (\n",
    "                X_mixture_2.reshape(n_samples // 2, n_informative),\n",
    "                X_mixture.reshape(n_samples // 2, n_informative),\n",
    "            )\n",
    "        )\n",
    "    elif simulation == \"trunk_mix\":\n",
    "        mixture_idx = rng.choice(2, n_samples // 2, replace=True, shuffle=True, p=[mix, 1 - mix])\n",
    "        norm_params = [[mu_0, cov], [mu_1, cov]]\n",
    "        X_mixture = np.fromiter(\n",
    "            (\n",
    "                rng.multivariate_normal(*(norm_params[i]), size=1, method=method)\n",
    "                for i in mixture_idx\n",
    "            ),\n",
    "            dtype=np.dtype((float, n_informative)),\n",
    "        )\n",
    "\n",
    "        X = np.vstack(\n",
    "            (\n",
    "                rng.multivariate_normal(\n",
    "                    np.zeros(n_informative), cov, n_samples // 2, method=method\n",
    "                ),\n",
    "                X_mixture.reshape(n_samples // 2, n_informative),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Simulation must be: trunk, trunk_overlap, trunk_mix\"\n",
    "        )\n",
    "\n",
    "    if n_dim > n_informative:\n",
    "        X = np.hstack((X, rng.normal(loc=0, scale=1, size=(X.shape[0], n_dim - n_informative))))\n",
    "\n",
    "    y = np.concatenate((np.zeros(n_samples // 2), np.ones(n_samples // 2)))\n",
    "\n",
    "    if return_params:\n",
    "        returns = [X, y]\n",
    "        if simulation == \"trunk\":\n",
    "            returns += [[mu_0, mu_1], [cov, cov]]\n",
    "        elif simulation == \"trunk-overlap\":\n",
    "            returns += [[np.zeros(n_informative), np.zeros(n_informative)], [cov, cov]]\n",
    "        elif simulation == \"trunk-mix\":\n",
    "            returns += [*list(zip(*norm_params)), X_mixture]\n",
    "        return returns\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d844e0-421b-4de9-8736-8bb4b0ff2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dcorr_PCA:\n",
    "    def test(self, x, y):\n",
    "        n_components = 'mle'\n",
    "        x_pca = PCA(n_components=n_components).fit_transform(x)\n",
    "        return Dcorr().test(x_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec8ea19-651c-46fa-9f6d-02309c767c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hypoRF:\n",
    "    def __init__(self, n_estimators=2000):\n",
    "        self.n_estimators = n_estimators\n",
    "\n",
    "    def statistic(self, X, y):\n",
    "        clf = RandomForestClassifier(n_estimators=self.n_estimators, oob_score=True)\n",
    "        clf.fit(X, y)\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        return oob_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5844e57-2ef5-409e-975b-ca0931ffe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(color_codes=True, style='ticks', context='talk', font_scale=1.5)\n",
    "PALETTE = sns.color_palette(\"Set1\")\n",
    "sns.set_palette(PALETTE[2:5] + PALETTE[6:], n_colors=9)\n",
    "\n",
    "SAMP_SIZES = [256, 512, 1024, 2048, 4096]\n",
    "DIM = 4096\n",
    "REPS = range(1000)\n",
    "P = 4096\n",
    "\n",
    "SAVE_PATH = \"p-{}_n-{}_{}\".format(int(DIM), int(SAMP_SIZES[0]), int(SAMP_SIZES[-1]))\n",
    "FIG_PATH = \"figs\"\n",
    "\n",
    "SIMULATIONS = {\n",
    "    \"Linear\": {\"simulation\" : \"trunk\"},\n",
    "    \"Nonlinear\": {\"simulation\" : \"trunk_mix\", \"mu_1\" : 5, \"mix\" : 0.75},\n",
    "    \"Independent\": {\"simulation\" : \"trunk_overlap\", \"mu_1\" : 5, \"mix\" : 0.75},\n",
    "}\n",
    "\n",
    "TESTS = {\n",
    "    # \"Dcorr\" : Dcorr(),\n",
    "    # \"Dcorr_PCA\" : Dcorr_PCA(),\n",
    "    \"hypoRF\" : hypoRF(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec4f6dd-9dca-4c37-98cc-962da1194261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _indep_sim_gen(X, n):\n",
    "    \"\"\"\n",
    "    Generate x, y from each sim\n",
    "    \"\"\"\n",
    "    X_t = np.concatenate((X[: n // 2], X[SAMP_SIZES[-1] // 2 : SAMP_SIZES[-1] // 2 + n // 2]))\n",
    "    y_t = np.concatenate((np.zeros(n // 2), np.ones(n // 2)))\n",
    "    return X_t, y_t\n",
    "\n",
    "\n",
    "def _perm_stat(est, X, n=100):\n",
    "    \"\"\"\n",
    "    Generates null and alternate distributions\n",
    "    \"\"\"\n",
    "    X, y = _indep_sim_gen(X, n)\n",
    "    obs_stat = est.statistic(X, y)\n",
    "    permy = np.random.permutation(y)\n",
    "    perm_stat = est.statistic(X, permy)\n",
    "\n",
    "    return obs_stat, perm_stat\n",
    "\n",
    "\n",
    "def _nonperm_pval(est, X, n=100):\n",
    "    \"\"\"\n",
    "    Generates fast  permutation pvalues\n",
    "    \"\"\"\n",
    "    X, y = _indep_sim_gen(X, n)\n",
    "    pvalue = est.test(X, y)[1]\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb8cdd6-92af-4246-8480-f5e42702eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_null(rep, est, est_name, sim, n=100, **sim_kwargs):\n",
    "    \"\"\"\n",
    "    Calculates empirical null and alternate distribution for each test.\n",
    "    \"\"\"\n",
    "    X, _ = make_trunk_classification(\n",
    "        n_samples=SAMP_SIZES[-1],\n",
    "        n_dim=DIM,\n",
    "        n_informative=1,\n",
    "        seed=rep,\n",
    "        **sim_kwargs\n",
    "    )\n",
    "    if est_name == \"hypoRF\":\n",
    "        alt_dist, null_dist = _perm_stat(est, X, n)\n",
    "        np.savetxt(\"{}/{}_{}_{}_{}.txt\".format(SAVE_PATH, sim.lower(), est_name, n, rep), [alt_dist, null_dist], delimiter=\",\")\n",
    "    else:\n",
    "        pval = _nonperm_pval(est, X, n)\n",
    "        np.savetxt(\"{}/{}_{}_{}_{}.txt\".format(SAVE_PATH, sim.lower(), est_name, n, rep), [pval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264ffc47-351a-4dc1-9d23-1e83db0bf4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433850a5d2b84bb19916654e69079855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28e1d8f621749b48201131c90e4a504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'p-4096_n-256_4096/linear_Dcorr_256_0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sim, sim_kwargs \u001b[38;5;129;01min\u001b[39;00m SIMULATIONS\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m samp_size \u001b[38;5;129;01min\u001b[39;00m SAMP_SIZES:\n\u001b[0;32m----> 8\u001b[0m                 \u001b[43mcompute_null\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamp_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msim_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# _ = Parallel(n_jobs=-1, verbose=100)(\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     [\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         delayed(compute_null)(rep, est, est_name, sim, n=samp_size, sim_kwargs=sim_kwargs)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     ]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mcompute_null\u001b[0;34m(rep, est, est_name, sim, n, p, sim_kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m X, _ \u001b[38;5;241m=\u001b[39m make_trunk_classification(\n\u001b[1;32m      6\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39mSAMP_SIZES[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      7\u001b[0m     n_dim\u001b[38;5;241m=\u001b[39mDIM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msim_kwargs\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m pval \u001b[38;5;241m=\u001b[39m _nonperm_pval(est, X, n)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cancer/lib/python3.11/site-packages/numpy/lib/npyio.py:1556\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;66;03m# datasource doesn't support creating a new file ...\u001b[39;00m\n\u001b[0;32m-> 1556\u001b[0m     \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1557\u001b[0m     fh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m   1558\u001b[0m     own_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'p-4096_n-256_4096/linear_Dcorr_256_0.txt'"
     ]
    }
   ],
   "source": [
    "# Run this block to regenerate power curves. Note that this takes a very long time!\n",
    "\n",
    "_ = Parallel(n_jobs=24, verbose=100)(\n",
    "    [\n",
    "        delayed(compute_null)(rep, est, est_name, sim, n=samp_size, **sim_kwargs)\n",
    "        for rep in REPS\n",
    "        for est_name, est in TESTS.items()\n",
    "        for sim, sim_kwargs in SIMULATIONS.items()\n",
    "        for samp_size in SAMP_SIZES\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd00d1-f5ce-4cfa-97ee-f56ae23b5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05\n",
    "FIG_REPS = 1000\n",
    "NROWS, NCOLS = 3, 5\n",
    "PLOT_KWARGS = {\n",
    "    \"Dcorr\" : {\"color\" : \"#377eb8\"},\n",
    "    \"Dcorr_PCA\" : {\"color\" : \"#999999\"},\n",
    "    \"MIGHT\" : {\"color\" : \"#e41a1c\", \"lw\" : 4},\n",
    "    \"MIGHT-sktree\" : {\"color\" : \"#e41a1c\", \"lw\" : 4, \"linestyle\" : \"--\"},\n",
    "    \"MIGHT-Coleman\" : {\"color\" : \"#e41a1c\", \"lw\" : 4, \"linestyle\" : \":\"},\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(nrows=NROWS, ncols=NCOLS, figsize=(28, 14))\n",
    "\n",
    "for i, row in enumerate(ax):\n",
    "    for j, col in enumerate(row):\n",
    "        count = NCOLS * i + j\n",
    "        \n",
    "        if count != 14:\n",
    "            col.axhline(y=0.05, linestyle=\":\", color=\"#000000\", label=\"Significance Level\")\n",
    "            for test_key in list(TESTS.keys()):\n",
    "                test_name = test_key.replace(\"_\", \" \")\n",
    "    \n",
    "                sim_name = list(SIMULATIONS.keys())[count]\n",
    "    \n",
    "                title = SIMULATIONS[sim_name]\n",
    "                power = []\n",
    "                for samp_size in SAMP_SIZES:\n",
    "                    file_name = \"{}/{}_{}_{}\".format(SAVE_PATH, sim_name, test_key, samp_size)\n",
    "                    if test_key in [\"MIGHT\", \"MIGHT-sktree\"]:\n",
    "                        alt_dist, null_dist = map(\n",
    "                            np.float64,\n",
    "                            zip(*[\n",
    "                                np.genfromtxt(\"{}_{}.txt\".format(file_name, rep))\n",
    "                                for rep in range(FIG_REPS)\n",
    "                            ]),\n",
    "                        )\n",
    "                        cutoff = np.sort(null_dist)[math.ceil(FIG_REPS * (1 - ALPHA))]\n",
    "                        empirical_power = (1 + (alt_dist >= cutoff).sum()) / (1 + FIG_REPS)\n",
    "                    else:\n",
    "                        pvals = np.array([\n",
    "                            np.genfromtxt(\"{}_{}.txt\".format(file_name, rep))\n",
    "                            for rep in range(FIG_REPS)\n",
    "                        ])\n",
    "                        empirical_power = (1 + (pvals <= ALPHA).sum()) / (1 + FIG_REPS)\n",
    "                    power.append(empirical_power)\n",
    "                \n",
    "                # print(power)\n",
    "                col.plot(SAMP_SIZES, power, label=test_name, **PLOT_KWARGS[test_key])\n",
    "            col.set_ylim(0, 1.01)\n",
    "            col.set_yticks([])\n",
    "            col.set_xticks([])\n",
    "            col.set_yticks([0, 1])\n",
    "            col.set_xticks([50, 500, 1000], [100, 1000, 2000])\n",
    "            if j == 0:\n",
    "                col.set_ylabel(\"Power for\\n4096 Variables\")\n",
    "            if i == NROWS - 1:\n",
    "                col.set_xlabel(\"Sample Size\")\n",
    "            if i == NROWS - 2 and j == NCOLS - 1:\n",
    "                col.set_xlabel(\"Sample Size\")\n",
    "            col.set_title(title)\n",
    "            sns.despine(right=True)\n",
    "        else:\n",
    "            col.set_axis_off()\n",
    "\n",
    "leg = row[0].legend(\n",
    "    bbox_to_anchor=(0.85, 0.3),\n",
    "    bbox_transform=plt.gcf().transFigure,\n",
    "    ncol=1,\n",
    "    loc=\"upper center\",\n",
    "    reverse=True\n",
    ")\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "for legobj in leg.legend_handles:\n",
    "        legobj.set_linewidth(5.0)\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "plt.savefig(FIG_PATH + '/all_power_sampsize.svg', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa0cf4a8-0dcc-4c1c-9cc0-2caab3bd4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_trunk_classification(\n",
    "    n_samples=5,\n",
    "    n_dim=10,\n",
    "    n_informative=1,\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d056ce53-ca09-47c0-800c-5313056c31b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components='mle' is only supported if n_samples >= n_features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_pca \u001b[38;5;241m=\u001b[39m \u001b[43mPCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m Dcorr()\u001b[38;5;241m.\u001b[39mtest(x_pca, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/cancer/lib/python3.11/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cancer/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:428\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    412\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/cancer/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:514\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m~/miniconda3/envs/cancer/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:526\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_components \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m n_features:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m         )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[1;32m    534\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: n_components='mle' is only supported if n_samples >= n_features"
     ]
    }
   ],
   "source": [
    "x_pca = PCA(n_components='mle').fit(X)\n",
    "Dcorr().test(x_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65721c-b2ab-4ceb-89d1-7f57a68c0f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
