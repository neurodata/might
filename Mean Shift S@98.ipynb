{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c5613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sktree.ensemble import HonestForestClassifier\n",
    "from sktree.stats import build_hyppo_oob_forest\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11554cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal, entropy\n",
    "from scipy.integrate import nquad\n",
    "\n",
    "\n",
    "def make_trunk_classification(\n",
    "    n_samples,\n",
    "    n_dim=10,\n",
    "    n_informative=1,\n",
    "    mu_1=1.0,\n",
    "    m_factor: int = -1,\n",
    "    cov_par: int = 1,\n",
    "    rho: int = 0,\n",
    "    band_type: str = \"ma\",\n",
    "    return_params: bool = False,\n",
    "    mix: int = 0,\n",
    "    seed=None,\n",
    "):\n",
    "    if n_dim < n_informative:\n",
    "        raise ValueError(\n",
    "            f\"Number of informative dimensions {n_informative} must be less than number \"\n",
    "            f\"of dimensions, {n_dim}\"\n",
    "        )\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    mu_1 = np.array([mu_1 / np.sqrt(i) for i in range(1, n_informative + 1)])\n",
    "    mu_0 = np.array([0 / np.sqrt(i) for i in range(1, n_informative + 1)])\n",
    "\n",
    "    if rho != 0:\n",
    "        if band_type == \"ma\":\n",
    "            cov = _moving_avg_cov(n_informative, rho)\n",
    "        elif band_type == \"ar\":\n",
    "            cov = _autoregressive_cov(n_informative, rho)\n",
    "        else:\n",
    "            raise ValueError(f'Band type {band_type} must be one of \"ma\", or \"ar\".')\n",
    "    else:\n",
    "        cov = cov_par * np.identity(n_informative)\n",
    "\n",
    "    if mix < 0 or mix > 1:\n",
    "        raise ValueError(\"Mix must be between 0 and 1.\")\n",
    "\n",
    "    if n_informative > 1000:\n",
    "        method = \"cholesky\"\n",
    "    else:\n",
    "        method = \"svd\"\n",
    "\n",
    "    if mix == 0:\n",
    "        X = np.vstack(\n",
    "            (\n",
    "                rng.multivariate_normal(mu_0, cov, n_samples // 2, method=method),\n",
    "                rng.multivariate_normal(mu_1, cov, n_samples // 2, method=method),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        mixture_idx = rng.choice(\n",
    "            [0, 1], n_samples // 2, replace=True, shuffle=True, p=[mix, 1 - mix]\n",
    "        )\n",
    "        X_mixture = np.zeros((n_samples // 2, len(mu_1)))\n",
    "        for idx in range(n_samples // 2):\n",
    "            if mixture_idx[idx] == 1:\n",
    "                X_sample = rng.multivariate_normal(mu_1, cov, 1, method=method)\n",
    "            else:\n",
    "                X_sample = rng.multivariate_normal(mu_0, cov, 1, method=method)\n",
    "            X_mixture[idx, :] = X_sample\n",
    "\n",
    "        X = np.vstack(\n",
    "            (\n",
    "                rng.multivariate_normal(\n",
    "                    np.zeros(n_informative), cov, n_samples // 2, method=method\n",
    "                ),\n",
    "                X_mixture,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if n_dim > n_informative:\n",
    "        # X = np.hstack((X, rng.uniform(low=0, high=1, size=(n_samples, n_dim - n_informative))))\n",
    "        X = np.hstack(\n",
    "            (\n",
    "                X,\n",
    "                rng.multivariate_normal(\n",
    "                    np.zeros(n_dim - n_informative),\n",
    "                    cov_par * np.identity(n_dim - n_informative),\n",
    "                    n_samples,\n",
    "                    method=method,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    y = np.concatenate((np.zeros(n_samples // 2), np.ones(n_samples // 2)))\n",
    "\n",
    "    if return_params:\n",
    "        return X, y, [mu_0, mu_1], [cov, cov]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99288897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "1\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "2\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "3\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "4\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "5\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "6\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZES = [256, 512, 1024, 2048, 4096]\n",
    "FIXED_SIZE = 4096\n",
    "N_ITR = 10\n",
    "\n",
    "def _parallel_stats(n_iter, samp_size):\n",
    "    X, y = make_trunk_classification(\n",
    "        n_samples=j, n_dim=dim, n_informative=1, seed=n_iter\n",
    "    )\n",
    "    est = drf()\n",
    "    est.fit(X, y)\n",
    "    statistic = est.predict(newdata=X_test, functional=\"cor\")\n",
    "    return statistic\n",
    "\n",
    "outputs = Parallel(n_jobs=-1, verbose=100)(\n",
    "    [\n",
    "        delayed(_parallel_stats)(n_iter, samp_size)\n",
    "        for n_iter in range(N_ITR)\n",
    "        for samp_size in SAMPLE_SIZES\n",
    "    ]\n",
    ")\n",
    "\n",
    "observe_probas = []\n",
    "null_probas = []\n",
    "for i in range(N_ITR):\n",
    "    print(i)\n",
    "    observe_probas.append([])\n",
    "    null_probas.append([])\n",
    "    for j in SAMPLE_SIZES:\n",
    "        print(j)\n",
    "        dim = FIXED_SIZE\n",
    "        X, y = make_trunk_classification(\n",
    "            n_samples=j, n_dim=dim, n_informative=1, seed=i\n",
    "        )\n",
    "\n",
    "        est = HonestForestClassifier(\n",
    "            n_estimators=2000,\n",
    "            max_samples=1.6,\n",
    "            max_features=0.3,\n",
    "            bootstrap=True,\n",
    "            stratify=True,\n",
    "            n_jobs=-2,\n",
    "            random_state=i,\n",
    "        )\n",
    "        _, observe_proba = build_hyppo_oob_forest(est, X, y)\n",
    "        observe_probas[i].append(observe_proba)\n",
    "        with open(\"observe_pos_mean_shift.pkl\", \"wb\") as f:\n",
    "            pickle.dump(observe_probas, f)\n",
    "\n",
    "        np.random.shuffle(y)\n",
    "        _, null_proba = build_hyppo_oob_forest(est, X, y)\n",
    "        null_probas[i].append(null_proba)\n",
    "        with open(\"null_pos_mean_shift.pkl\", \"wb\") as f:\n",
    "            pickle.dump(null_probas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_SA98(y_true, y_pred_proba, max_fpr=0.02) -> float:\n",
    "    if y_true.squeeze().ndim != 1:\n",
    "        raise ValueError(f\"y_true must be 1d, not {y_true.shape}\")\n",
    "    if 0 in y_true or -1 in y_true:\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            y_true, y_pred_proba[:, 1], pos_label=1, drop_intermediate=False\n",
    "        )\n",
    "    else:\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            y_true, y_pred_proba[:, 1], pos_label=2, drop_intermediate=False\n",
    "        )\n",
    "    s98 = max([tpr for (fpr, tpr) in zip(fpr, tpr) if fpr <= max_fpr])\n",
    "    return s98\n",
    "\n",
    "\n",
    "def Calculate_MI(y_true, y_pred_proba):\n",
    "    H_YX = np.mean(entropy(y_pred_proba, base=np.exp(1), axis=1))\n",
    "    # empirical count of each class (n_classes)\n",
    "    _, counts = np.unique(y_true, return_counts=True)\n",
    "    H_Y = entropy(counts, base=np.exp(1))\n",
    "    return H_Y - H_YX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = []\n",
    "NULL_POS = []\n",
    "for i in range(N_ITR):\n",
    "    POS.append([])\n",
    "    NULL_POS.append([])\n",
    "    for j in range(len(SAMPLE_SIZES)):\n",
    "        POS[i].append(np.nanmean(observe_probas[i][j], axis=0))\n",
    "        NULL_POS[i].append(np.nanmean(null_probas[i][j], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ce6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA98 = []\n",
    "NULL_SA98 = []\n",
    "for j in range(len(SAMPLE_SIZES)):\n",
    "    y = np.concatenate((np.zeros(SAMPLE_SIZES[j] // 2), np.ones(SAMPLE_SIZES[j] // 2)))\n",
    "    \n",
    "    temp_SA98 = []\n",
    "    temp_null_SA98 = []\n",
    "    for i in range(N_ITR):\n",
    "        temp_SA98.append(Calculate_SA98(y, POS[i][j]))\n",
    "        temp_null_SA98.append(Calculate_SA98(y, NULL_POS[i][j]))\n",
    "        \n",
    "    SA98.append(temp_SA98)\n",
    "    NULL_SA98.append(temp_null_SA98)\n",
    "\n",
    "SA98 = np.array(SA98)\n",
    "NULL_SA98 = np.array(NULL_SA98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27304132",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI = []\n",
    "NULL_MI = []\n",
    "for j in range(len(SAMPLE_SIZES)):\n",
    "    y = np.concatenate((np.zeros(SAMPLE_SIZES[j] // 2), np.ones(SAMPLE_SIZES[j] // 2)))\n",
    "    \n",
    "    temp_MI = []\n",
    "    temp_null_MI = []\n",
    "    for i in range(N_ITR):\n",
    "        temp_MI.append(Calculate_MI(y, POS[i][j]))\n",
    "        temp_null_MI.append(Calculate_MI(y, NULL_POS[i][j]))\n",
    "        \n",
    "    MI.append(temp_MI)\n",
    "    NULL_MI.append(temp_null_MI)\n",
    "    \n",
    "MI = np.array(MI)\n",
    "NULL_MI = np.array(NULL_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = []\n",
    "NULL_ACC = []\n",
    "for j in range(len(SAMPLE_SIZES)):\n",
    "    y = np.concatenate((np.zeros(SAMPLE_SIZES[j] // 2), np.ones(SAMPLE_SIZES[j] // 2)))\n",
    "    \n",
    "    temp_ACC = []\n",
    "    temp_null_ACC = []\n",
    "    for i in range(N_ITR):\n",
    "        temp_ACC.append(accuracy_score(y, np.where(POS[i][j] > 0.5, 1, 0)[:,1]))\n",
    "        temp_null_ACC.append(accuracy_score(y, np.where(NULL_POS[i][j] > 0.5, 1, 0)[:,1]))\n",
    "        \n",
    "    ACC.append(temp_ACC)\n",
    "    NULL_ACC.append(temp_null_ACC)\n",
    "\n",
    "ACC = np.array(ACC)\n",
    "NULL_ACC = np.array(NULL_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "ALPHA = 0.05\n",
    "\n",
    "SA98_POWERS = []\n",
    "for i in range(len(SAMPLE_SIZES)):\n",
    "    cutoff = np.sort(NULL_SA98[i])[math.ceil(N_ITR * (1 - ALPHA)) - 1]\n",
    "    power = (1 + (SA98[i] >= cutoff).sum()) / (1 + N_ITR)\n",
    "    SA98_POWERS.append(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_POWERS = []\n",
    "for i in range(len(SAMPLE_SIZES)):\n",
    "    cutoff = np.sort(NULL_MI[i])[math.ceil(N_ITR * (1 - ALPHA)) - 1]\n",
    "    power = (1 + (MI[i] >= cutoff).sum()) / (1 + N_ITR)\n",
    "    MI_POWERS.append(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0745ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_POWERS = []\n",
    "for i in range(len(SAMPLE_SIZES)):\n",
    "    cutoff = np.sort(NULL_ACC[i])[math.ceil(N_ITR * (1 - ALPHA)) - 1]\n",
    "    power = (1 + (ACC[i] >= cutoff).sum()) / (1 + N_ITR)\n",
    "    ACC_POWERS.append(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_SIZES = [2**i for i in range(2, 13)]\n",
    "observe_dim_probas = []\n",
    "null_dim_probas = []\n",
    "for i in range(N_ITR):\n",
    "    print(i)\n",
    "    observe_dim_probas.append([])\n",
    "    null_dim_probas.append([])\n",
    "    for j in DIM_SIZES:\n",
    "        print(j)\n",
    "        X, y = make_trunk_classification(\n",
    "            n_samples=4096, n_dim=j, n_informative=1, seed=i\n",
    "        )\n",
    "\n",
    "        est = HonestForestClassifier(\n",
    "            n_estimators=2000,\n",
    "            max_samples=1.6,\n",
    "            max_features=0.3,\n",
    "            bootstrap=True,\n",
    "            stratify=True,\n",
    "            n_jobs=-2,\n",
    "            random_state=i,\n",
    "        )\n",
    "        _, observe_dim_proba = build_hyppo_oob_forest(est, X, y)\n",
    "        observe_dim_probas[i].append(observe_dim_proba)\n",
    "        with open(\"observe_pos_dim_mean_shift.pkl\", \"wb\") as f:\n",
    "            pickle.dump(observe_dim_probas, f)\n",
    "\n",
    "        np.random.shuffle(y)\n",
    "        _, null_dim_proba = build_hyppo_oob_forest(est, X, y)\n",
    "        null_dim_probas[i].append(null_dim_proba)\n",
    "        with open(\"null_pos_dim_mean_shift.pkl\", \"wb\") as f:\n",
    "            pickle.dump(null_dim_probas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07085077",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_DIM = []\n",
    "NULL_POS_DIM = []\n",
    "for i in range(N_ITR):\n",
    "    POS_DIM.append([])\n",
    "    NULL_POS_DIM.append([])\n",
    "    for j in range(len(DIM_SIZES)):\n",
    "        POS_DIM[i].append(np.nanmean(observe_dim_probas[i][j], axis=0))\n",
    "        NULL_POS_DIM[i].append(np.nanmean(null_dim_probas[i][j], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA98_DIM = []\n",
    "NULL_SA98_DIM = []\n",
    "for j in range(len(DIM_SIZES)):\n",
    "    y = np.concatenate((np.zeros(256 // 2), np.ones(256 // 2)))\n",
    "    \n",
    "    temp_SA98_DIM = []\n",
    "    temp_null_SA98_DIM = []\n",
    "    for i in range(N_ITR):\n",
    "        temp_SA98_DIM.append(Calculate_SA98(y, POS_DIM[i][j]))\n",
    "        temp_null_SA98_DIM.append(Calculate_SA98(y, NULL_POS_DIM[i][j]))\n",
    "        \n",
    "    SA98_DIM.append(temp_SA98_DIM)\n",
    "    NULL_SA98_DIM.append(temp_null_SA98_DIM)\n",
    "\n",
    "SA98_DIM = np.array(SA98_DIM)\n",
    "NULL_SA98_DIM = np.array(NULL_SA98_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA98_POWERS_DIM = []\n",
    "for i in range(len(DIM_SIZES)):\n",
    "    cutoff = np.sort(NULL_SA98_DIM[i])[math.ceil(N_ITR * (1 - ALPHA)) - 1]\n",
    "    power = (1 + (SA98_DIM[i] >= cutoff).sum()) / (1 + N_ITR)\n",
    "    SA98_POWERS_DIM.append(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_DIM = []\n",
    "NULL_MI_DIM = []\n",
    "for j in range(len(DIM_SIZES)):\n",
    "    y = np.concatenate((np.zeros(256 // 2), np.ones(256 // 2)))\n",
    "    \n",
    "    temp_MI_DIM = []\n",
    "    temp_null_MI_DIM = []\n",
    "    for i in range(N_ITR):\n",
    "        temp_MI_DIM.append(Calculate_MI(y, POS_DIM[i][j]))\n",
    "        temp_null_MI_DIM.append(Calculate_MI(y, NULL_POS_DIM[i][j]))\n",
    "        \n",
    "    MI_DIM.append(temp_MI_DIM)\n",
    "    NULL_MI_DIM.append(temp_null_MI_DIM)\n",
    "    \n",
    "MI_DIM = np.array(MI_DIM)\n",
    "NULL_MI_DIM = np.array(NULL_MI_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b13e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_POWERS_DIM = []\n",
    "for i in range(len(DIM_SIZES)):\n",
    "    cutoff = np.sort(NULL_MI_DIM[i])[math.ceil(N_ITR * (1 - ALPHA)) - 1]\n",
    "    power = (1 + (MI_DIM[i] >= cutoff).sum()) / (1 + N_ITR)\n",
    "    MI_POWERS_DIM.append(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_DIM = []\n",
    "NULL_ACC_DIM = []\n",
    "for j in range(len(DIM_SIZES)):\n",
    "    y = np.concatenate((np.zeros(256 // 2), np.ones(256 // 2)))\n",
    "    \n",
    "    temp_ACC_DIM = []\n",
    "    temp_null_ACC_DIM = []\n",
    "    for i in range(N_ITR):\n",
    "        temp_ACC_DIM.append(accuracy_score(y, np.where(POS_DIM[i][j] > 0.5, 1, 0)[:,1]))\n",
    "        temp_null_ACC_DIM.append(accuracy_score(y, np.where(NULL_POS_DIM[i][j] > 0.5, 1, 0)[:,1]))\n",
    "        \n",
    "    ACC_DIM.append(temp_ACC_DIM)\n",
    "    NULL_ACC_DIM.append(temp_null_ACC_DIM)\n",
    "\n",
    "ACC_DIM = np.array(ACC_DIM)\n",
    "NULL_ACC_DIM = np.array(NULL_ACC_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_POWERS_DIM = []\n",
    "for i in range(len(DIM_SIZES)):\n",
    "    cutoff = np.sort(NULL_ACC_DIM[i])[math.ceil(N_ITR * (1 - ALPHA)) - 1]\n",
    "    power = (1 + (ACC_DIM[i] >= cutoff).sum()) / (1 + N_ITR)\n",
    "    ACC_POWERS_DIM.append(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    color_codes=True, palette=\"bright\", style=\"ticks\", context=\"talk\", font_scale=1.5\n",
    ")\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), constrained_layout=True)\n",
    "for i, col in enumerate(ax):\n",
    "    col.set_xscale(\"log\")\n",
    "    col.set(ylim=(-0.02, 1.02), yticks=[0, 1])\n",
    "    if i == 0:\n",
    "        col.set_xlabel(\"Sample Size at 1D\")\n",
    "        col.set_ylabel(\"Power for 1D (0.5, 1)\")\n",
    "        col.plot(SAMPLE_SIZES, SA98_POWERS, color=\"red\", label=\"SA98\")\n",
    "        col.plot(SAMPLE_SIZES, MI_POWERS, color=\"blue\", label=\"MI\")\n",
    "        col.plot(SAMPLE_SIZES, ACC_POWERS, color=\"green\", label=\"Accuracy\")\n",
    "        col.axhline([0.05], color=\"black\", ls=\"--\", label=\"alpha\")\n",
    "    elif i == 1:\n",
    "        col.set_xlabel(\"Dimension at 256S\")\n",
    "        col.plot(DIM_SIZES, SA98_POWERS_DIM, color=\"red\")\n",
    "        col.plot(DIM_SIZES, MI_POWERS_DIM, color=\"blue\")\n",
    "        col.plot(DIM_SIZES, ACC_POWERS_DIM, color=\"green\")\n",
    "        col.axhline([0.05], color=\"black\", ls=\"--\")\n",
    "\n",
    "\n",
    "fig.align_ylabels(\n",
    "    ax[\n",
    "        :,\n",
    "    ]\n",
    ")\n",
    "\n",
    "leg = fig.legend(\n",
    "    bbox_to_anchor=(0.53, -0.15),\n",
    "    bbox_transform=plt.gcf().transFigure,\n",
    "    ncol=6,\n",
    "    loc=\"lower center\",\n",
    ")\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "for legobj in leg.legend_handles:\n",
    "    legobj.set_linewidth(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45818a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
